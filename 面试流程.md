1.先自我介绍，包含日常工作

2.父子线程怎么共享数据
interitableThreadLocals
当Thread创建时，将parent的map赋值copy给了当前线程中的inheritableThreadLocals。而copy过程都是浅copy，key,value都是引用地址的赋值。

3.lock和sync区别
3.1synchronized是Java中的一个关键字；
Lock是Java中的一个接口；
3.2synchronized可对实例方法、静态方法和代码块加锁；
Lock加锁针对当前线程；
3.3synchronized中叫做偏向锁；
Lock中叫做重入锁；
3.4synchronized：不能指定解锁操作，执行完代码块的对象会自动释放锁；
Lock：可调用ulock方法去释放锁比synchronized更灵活；

4.HashMap1.7、1.8区别
1.8主要优化减少了Hash冲突 ，提高哈希表的存、取效率。

底层数据结构不一样，1.7是数组+链表，1.8则是数组+链表+红黑树结构（当链表长度大于8，转为红黑树）。
JDK1.8中resize()方法在表为空时，创建表；在表不为空时，扩容；而JDK1.7中resize()方法负责扩容，inflateTable()负责创建表。
 1.8中没有区分键为null的情况，而1.7版本中对于键为null的情况调用putForNullKey()方法。但是两个版本中如果键为null，那么调用hash()方法得到的都将是0，所以键为null的元素都始终位于哈希表table【0】中。
当1.8中的桶中元素处于链表的情况，遍历的同时最后如果没有匹配的，直接将节点添加到链表尾部；而1.7在遍历的同时没有添加数据，而是另外调用了addEntry()方法，将节点添加到链表头部。
1.7中新增节点采用头插法，1.8中新增节点采用尾插法。这也是为什么1.8不容易出现环型链表的原因。
1.7中是通过更改hashSeed值修改节点的hash值从而达到rehash时的链表分散，而1.8中键的hash值不会改变，rehash时根据（hash&oldCap）==0将链表分散。
 1.8rehash时保证原链表的顺序，而1.7中rehash时有可能改变链表的顺序（头插法导致）。
在扩容的时候：1.7在插入数据之前扩容，而1.8插入数据成功之后扩容。

5.AQS原理(执行过程源码，入队出队的细节，源码细节)
AQS 队列内部维护的是一个 FIFO 的双向链表，这种结构的特点是每个数据结构都有两个指针，分别指向直接的后继节点和直接前驱节点。所以双向链表可以从任
意一个节点开始很方便的访问前驱和后继。每个 Node 其实是由线程封装，当线程争抢锁失败后会封装成 Node 加入到 ASQ 队列中去；当获取锁的线程释放锁以
后，会从队列中唤醒一个阻塞的节点(线程)。
1. 新的线程封装成 Node 节点追加到同步队列中，设置 prev 节点以及修改当前节点的前置节点的 next 节点指向自己
2. 通过 CAS 讲 tail 重新指向新的尾部节点
head 节点表示获取锁成功的节点，当头结点在释放同步状态时，会唤醒后继节点，如果后继节点获得锁成功，会把自己设置为头结点。
入队
建立节点的构造方法并没有设置waitSatus，由于waitStatus是int类型的，在没有初始化的情况下就是0，所以默认新建的Node其waitStatus就是0。
如果当前队列的tail不为Null，代表队列已经初始化，那么就自旋CAS加入队列。这里使用CAS来保证并发安全下的安全性，每次CAS之前都会再次取出当前的tail。
如果当前队列的tail为Null，代表队列没有初始化，调用CAS创建Head。这里也用了CAS，同样为了保证并发安全性，且创建完成后队列的head=tail，而且会继续下一次循环，说明队列里有一个冗余节点(dummy head)


出队
调用被重写的tryRelease方法释放锁。之所以这里加上if判断，是为了解决锁重入的情况下，必须把所持有的所有重入的锁都释放才可以唤醒后继节点
判断是否需要唤醒后继节点，h.waitStatus！=0其实就是<0，即后面是否有等待的节点
唤醒后继节点

    public final boolean release(int arg) {
        if (tryRelease(arg)) {
            Node h = head;
            if (h != null && h.waitStatus != 0)
                unparkSuccessor(h);
            return true;
        }
        return false;
    }
清除等待标志位。只用了一个cas操作而非循环cas，也就意味着清除等待标志位是允许失败的
找到下一个需要被唤醒的节点
唤醒节点

     private void unparkSuccessor(Node node) {
           /*
            * If status is negative (i.e., possibly needing signal) try
            * to clear in anticipation of signalling.  It is OK if this
            * fails or if status is changed by waiting thread.
            */
           int ws = node.waitStatus;
           if (ws < 0)
               compareAndSetWaitStatus(node, ws, 0);

        /*
         * Thread to unpark is held in successor, which is normally
         * just the next node.  But if cancelled or apparently null,
         * traverse backwards from tail to find the actual
         * non-cancelled successor.
         */
        Node s = node.next;
        if (s == null || s.waitStatus > 0) {
            s = null;
            for (Node t = tail; t != null && t != node; t = t.prev)
                if (t.waitStatus <= 0)
                    s = t;
        }
        if (s != null)
            LockSupport.unpark(s.thread);
    }


源码细节
AQS分为独占模式和共享模式。
所谓独占模式，指的是资源本身，在具体时刻内，最多只能被一个线程持有。
在入队完毕之后，就进入等待，和不断被唤醒尝试抢占的过程。
独占式获取，还有一种情况就是带超时时间的独占获取。其实基本思路都是一致，只不过在线程挂起的时候，不再是永久性的挂起，而是有超时时间的挂起。

共享模式对于独占模式而言，最主要的区别就是同一时刻，持有资源的线程可以超过1个。

为什么需要SIGNAL状态
在共享唤醒中，多线程并发争夺唤醒权，必然存在一个cas的过程。也就是需要一个从有状态值cas到0的过程。所以要存在这样的一个状态值，最后就是SIGNAL了。从另外一个角度来看，节点一旦进入取消状态就不可恢复，因此需要存在一个不同的状态用来表示该节点需要唤醒，这也就是signal。

为什么需要PROPAGATE状态
在共享唤醒中，所有的节点都不断的抢夺唤醒权是没有意义而且浪费的。同时需要一个与初始状态不同的状态用来表达多线程竞争唤醒权的结果。因为从SIGNAL到0是表示唤醒权被某一个线程抢夺完成，因此需要有一个额外的状态可以用来通知其他竞争线程可以停止竞争了。所以就有了 PROPAGATE状态。

6.CountDownLatch和CyclicBarrier的区别是什么
源码级别

CountDownLatch和CyclicBarrier都有让多个线程等待同步然后再开始下一步动作的意思，但是CountDownLatch的下一步的动作实施者是主线程，具有不可重复性；而CyclicBarrier的下一步动作实施者还是“其他线程”本身，具有往复多次实施动作的特点。

CyclicBarrier是通过显示锁ReentrantLock来锁存对象
barrier的步骤。n-1个线程进去await方法后，都在for(;;)等待。
直到最后一个线程进入await后,将其他所有线程唤醒。

CountDownLatch使用了AbstractQueuedSynchronizer作为辅助类，这是一个适用于所有使用int值作为state状态量的同步辅助类。

并且重写了tryAcquireShared(),tryReleaseShared(),调用了一个Unsafe的本地CAS方法(CompareAndSet).
第二个核心方法await()是在AbstractQueuedSynchronizer类中doAcquireSharedInterruptibly(int arg)


7.volatile从指令重排序，内存屏障，聊到总线风暴

volatile
7.1.保证此变量对所有的线程的可见性，这里的“可见性”，如本文开头所述，当一个线程修改了这个变量的值，volatile 保证了新值能立即同步到主内存，以及每次使用前立即从主内存刷新。但普通变量做不到这点，普通变量的值在线程间传递均需要通过主内存。

7.2.禁止指令重排序优化。有volatile修饰的变量，赋值后多执行了一个“load addl $0x0, (%esp)”操作，这个操作相当于一个内存屏障（指令重排序时不能把后面的指令重排序到内存屏障之前的位置），只有一个CPU访问内存时，并不需要内存屏障；（什么是指令重排序：是指CPU采用了允许将多条指令不按程序规定的顺序分开发送给各相应电路单元处理）。

内存屏障
内存屏障分为两种：Load Barrier 和 Store Barrier即读屏障和写屏障。
内存屏障有两个作用：

1.阻止屏障两侧的指令重排序；
2.强制把写缓冲区/高速缓存中的脏数据等写回主内存，让缓存中相应的数据失效。

对于Load Barrier来说，在指令前插入Load Barrier，可以让高速缓存中的数据失效，强制从新从主内存加载数据；
对于Store Barrier来说，在指令后插入Store Barrier，能让写入缓存中的最新数据更新写入主内存，让其他线程可见。
java的内存屏障通常所谓的四种即LoadLoad,StoreStore,LoadStore,StoreLoad实际上也是上述两种的组合，完成一系列的屏障和数据同步功能。

LoadLoad屏障：对于这样的语句Load1; LoadLoad; Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。
StoreStore屏障：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。
LoadStore屏障：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。
StoreLoad屏障：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。它的开销是四种屏障中最大的。在大多数处理器的实现中，这个屏障是个万能屏障，兼具其它三种内存屏障的功能

volatile的内存屏障策略非常严格保守，非常悲观且毫无安全感的心态：

在每个volatile写操作前插入StoreStore屏障，在写操作后插入StoreLoad屏障；
在每个volatile读操作前插入LoadLoad屏障，在读操作后插入LoadStore屏障；

由于内存屏障的作用，避免了volatile变量和其它指令重排序、线程之间实现了通信，使得volatile表现出了锁的特性。

总线风暴
由于volatile的mesi缓存一致性协议需要不断的从主内存嗅探和cas不断循环无效交互导致总线带宽达到峰值。
解决办法：部分volatile和cas使用synchronize。

知识补充
Java内存模型
Java内存模型规定了所有的变量都存储在主内存（Main Memory）中，此外每条线程还有自己的工作内存（Working Memory）。

线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，不能直接读写主内存中的变量。

并且，不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值得传递均需要通过主内存来完成，线程、主内存、工作内存关系如下图



8.mysql索引：聚集索引、非聚集索引、索引结构，顺带问各种树的特性
聚集索引，该索引中键值的逻辑顺序决定了表中相应行的物理顺序。
非聚集索引，该索引中索引的逻辑顺序与磁盘上行的物理存储顺序不同。
聚簇索引：索引的叶节点就是数据节点。而非聚簇索引的叶节点仍然是索引节点，只不过有一个指针指向对应的数据块。
聚集索引


9.举例优化sql

10.MVCC和事务隔离级别的关系
MVCC（Multi-Version Concurrency Control ，多版本并发控制）指的就是在使用READ COMMITTD、REPEATABLE READ这两种隔离级别的事务在执行普通的SEELCT操作时访问记录的版本链的过程，这样子可以使不同事务的读-写、写-读操作并发执行，从而提升系统性能。READ COMMITTD、REPEATABLE READ这两个隔离级别的一个很大不同就是生成ReadView的时机不同，READ COMMITTD在每一次进行普通SELECT操作前都会生成一个ReadView，而REPEATABLE READ只在第一次进行普通SELECT操作前生成一个ReadView，之后的查询操作都重复这个ReadView就好了。

11.间隙锁、行锁、乐观锁悲观锁等
间隙锁
当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。
因为Query执行过程中通过过范围查找的话，他会锁定整个范围内所有的索引键值，即使这个键值并不存在。
间隙锁有一个比较致命的弱点，就是当锁定一个范围键值之后，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害  
优化建议：
尽可能让所有数据检索都通过索引来完成，避免无索引行锁升级为表锁。
合理设计索引，尽量缩小锁的范围
尽可能较少检索条件，避免间隙锁
尽量控制事务大小，减少锁定资源量和时间长度
尽可能低级别事务隔离

行锁
特点：偏向InnoDB存储引擎，开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低,并发度也最高。
行锁支持事务
行为：
1、当我们对一行进行更新但是不提交的时候，其他进程也对该行进行更新则需要进行等待，这就是行锁。
2、如果我们对一行进行更新，其他进程更新别的行是不会受影响的。

悲观锁，是因为这是一种对数据的修改抱有悲观态度的并发控制方式。我们一般认为数据被并发修改的概率比较大，所以需要在修改之前先加锁。

悲观锁主要分为共享锁或排他锁

共享锁【Shared lock】又称为读锁，简称S锁。顾名思义，共享锁就是多个事务对于同一数据可以共享一把锁，都能访问到数据，但是只能读不能修改。
排他锁【Exclusive lock】又称为写锁，简称X锁。顾名思义，排他锁就是不能与其他锁并存，如果一个事务获取了一个数据行的排他锁，其他事务就不能再获取该行的其他锁，包括共享锁和排他锁，但是获取排他锁的事务是可以对数据行读取和修改。
悲观并发控制实际上是“先取锁再访问”的保守策略，为数据处理的安全提供了保证。
但是在效率方面，处理加锁的机制会让数据库产生额外的开销，还有增加产生死锁的机会。另外还会降低并行性，一个事务如果锁定了某行数据，其他事务就必须等待该事务处理完才可以处理那行数据。

乐观锁是相对悲观锁而言，也是为了避免数据库幻读、业务处理时间过长等原因引起数据处理错误的一种机制，但乐观锁不会刻意使用数据库本身的锁机制，而是依据数据本身来保证数据的正确性。

相对于悲观锁，在对数据库进行处理的时候，乐观锁并不会使用数据库提供的锁机制。一般的实现乐观锁的方式就是记录数据版本。
乐观并发控制相信事务之间的数据竞争(data race)的概率是比较小的，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会产生任何锁和死锁。
悲观锁例子
使用select…for update把数据锁住，再commit。不过需要注意一些锁的级别，MySQL InnoDB默认行级锁。行级锁都是基于索引的，如果一条SQL语句用不到索引是不会使用行级锁的，会使用表级锁把整张表锁住，这点需要注意。



12.唯一索引和普通索引的区别


14.Mysql的log有哪些，分别用来解决什么问题

15.怎么看mysql有没有执行索引

16.explain的时候最关心哪些字段，分别是什么含义

17.讲下hashMap的底层结构，put操作怎么找到位置的,&运算等价于什么运算？为什么不是线程安全的，1.8是头插还是尾插？怎么保证线程安全

18.concurrentHashMap底层,1.7怎么扩容的，1.8怎么保证线程安全

19.Sychronized怎么实现的

20.作用于方法时锁的是什么，静态方法锁的是什么，怎么实现可重入的

21.CAS是什么，有什么缺点

22.ABA是怎么发生的，怎么解决ABA问题

23ReetrantLock有用过吗，怎么实现重入的

24.Volatile解决了什么问题，一般用在哪里

25.Jdk1.6对锁做了哪些优化

26.Spring的AOP的实现方式

27.什么是动态代理

28.Spring怎么解决循环依赖的

29.类加载机制是什么，讲下双亲委派

30讲下redis穿透

31。讲下布隆过滤器的实现机制

32.Redis为什么这么快

33.讲下redis击穿

34.垃圾回收器讲下

35.CMS怎么进行垃圾回收的

36.讲下垃圾回收算法

37.讲下对分布式的理解

38.有一个转盘，分三块，每块的中奖概率一样，怎么实现

39.做个朋友圈，需要注意哪些点


第五轮

1.项目介绍

2.听到说做了限流，限流标准(并发数？qps？并发数和qps关系？说出5种限流方案和对应的算法原理)

3.dubbo调用端怎么在jvm种生成对应服务？
dubbo服务端和调用端超时时间设置和区别、dubbo长连接。

4.mysql行锁最大并发数？(秒杀项目指出)

5.设计秒杀系统，我说的异步的方式，会问怎么优化？改为了同步的方式？异步和同步区别？


6.碰到哪些技术难点？怎么解决？有没有参考其他大厂？其他大厂方案什么样的？有没有关注阿里这边最新的技术？

7.刚刚的秒杀系统，会涉及到多个库表的更新，分布式事务怎么解决，我说的消息最终一致性，异步？有没有更好的方案？同步TCC方式，TCC方式原理？(三个阶段的具体实现)


